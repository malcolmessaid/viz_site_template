{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of F. Scott Fitzgerald's Evolution of Language across His First Three  Novels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to look at how F. Scott Fitzgerald's writing matured across his first three novels. Hopefully, by looking at what kind of language he uses, and the types of things he focuses on, I can tell a story of his maturation over time. I am interested in this topic becuase Fitzgerald is one of my favorite authors, and I have read all three of these books. I will create 2 graphs. The first will track the uses of main character names. The second will track the use of particular words of my choosing across the 3 novels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Side of Paradise(TSP): http://www.gutenberg.org/files/805/805-0.txt <br>\n",
    "The Beautiful and Damned(TBD): http://www.gutenberg.org/cache/epub/9830/pg9830.txt <br>\n",
    "The Great Gatsby(TGG):http://xroads.virginia.edu/~hyper2/Fitzgerald/gatsby.txt <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Books\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all of the data I want to collect. The character arrays are collections of the most important characters in each novel (I have picked those). The Track words are salient words I will track across the novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TSPwords = []\n",
    "TBDwords = []\n",
    "TGGwords = []\n",
    "\n",
    "\n",
    "TSPlength = 0\n",
    "TBDlength = 0\n",
    "TGGlength = 0\n",
    "\n",
    "TSPCharacters = ['amory' ,'beatrice', 'rosalind','isabelle']\n",
    "TBDCharacters = ['anthony', 'richard ', 'gloria', 'dot', 'dick']\n",
    "TGGCharacters = ['gatsby', 'tom', 'daisy', 'jordan']\n",
    "\n",
    "TSPCharacterList = {}\n",
    "TBDCharacterList = {}\n",
    "TGGCharacterList = {}\n",
    "\n",
    "AllCharacterList = []\n",
    "\n",
    "trackWords = ['love', 'girl', 'heart', 'city', 'money', 'white']\n",
    "\n",
    "TSPtrackWords = {}\n",
    "TBDtrackWords = {}\n",
    "TGGtrackWords = {}\n",
    "\n",
    "trackWordsAll = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Side of Paradise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TSP_URL = 'http://www.gutenberg.org/files/805/805-0.txt'\n",
    "resTSP = requests.get(TSP_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TSPStart = resTSP.text.index(\"BOOK ONE--\")\n",
    "TSPEnd = resTSP.text.index(\"Appendix: Production notes for eBook edition 11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "textTSP = resTSP.text[TSPStart:TSPEnd]\n",
    "#print (textTSP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Beautiful and Damned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TBD_URL = 'http://www.gutenberg.org/cache/epub/9830/pg9830.txt'\n",
    "resTBD = requests.get(TBD_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TBDStart = resTBD.text.index('CHAPTER I')\n",
    "TBDEnd = resTBD.text.index('End of the Project Gutenberg EBook of The Beautiful and the Damned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textTBD = resTBD.text[TBDStart:TBDEnd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(textTBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Great Gatsby: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TGG_URL = 'http://xroads.virginia.edu/~hyper2/Fitzgerald/gatsby.txt'\n",
    "resTGG = requests.get(TGG_URL)\n",
    "TGGStart = resTGG.text.index('Chapter 1')\n",
    "TGGEnd = resTGG.text.index('End of this Project Gutenberg of Australia eBook')\n",
    "\n",
    "textTGG = resTGG.text[TGGStart:TGGEnd]\n",
    "##print (textTGG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Text:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Side of Paradise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print (nltk.word_tokenize(textTSP[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tokenizer doesn't seem to get rid of punctuation, so i'll need to do that another way. I had to add some characters to the punctuation string because the file has quotation marks and apostrphes that go backwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print (string.punctuation)\n",
    "punct = string.punctuation + '’' + '”' + '“' + '(' + ')' + '_'+ \"\"\"''\"\"\" + '``' + '...' + '‘'\n",
    "#print (punct)\n",
    "TSPwords = nltk.word_tokenize(textTSP)\n",
    "TBDwords = nltk.word_tokenize(textTBD)\n",
    "TGGwords = nltk.word_tokenize(textTGG)\n",
    "    \n",
    "TSPlength = len(TSPwords)\n",
    "TBDlength = len(TBDwords)\n",
    "TGGlength = len(TGGwords)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "#stopwords.words('english').pop(0)\n",
    "\n",
    "stopWords = stopwords.words('english')\n",
    "#print (stopWords)\n",
    "stopWords.pop(0)\n",
    "#print (stopWords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102967\n",
      "151556\n",
      "59922\n"
     ]
    }
   ],
   "source": [
    "print (TSPlength)\n",
    "print (TBDlength)\n",
    "print (TGGlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def makeLower(arr):\n",
    "    for i, word in enumerate(arr):\n",
    "        del arr[i]\n",
    "        arr.insert(i, word.lower())\n",
    "        \n",
    "def fixNot(arr):\n",
    "    for i, word in enumerate(arr):\n",
    "        if word == \"n't\":\n",
    "            del arr[i]\n",
    "            arr.insert(i, 'not')\n",
    "\n",
    "\n",
    "#print (stopWords)\n",
    "\n",
    "def checkWord(word):\n",
    "    if word in punct:\n",
    "        return False\n",
    "    if word == '--':\n",
    "        return False\n",
    "    if word in stopWords:\n",
    "        return False\n",
    "    if word == 'CHAPTER':\n",
    "        return False\n",
    "    if word == \"'s\":\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "\n",
    "fixNot(TSPwords)\n",
    "fixNot(TBDwords)\n",
    "fixNot(TGGwords)\n",
    "\n",
    "makeLower(TSPwords)\n",
    "makeLower(TBDwords)\n",
    "makeLower(TGGwords)\n",
    "        \n",
    "\n",
    "TSPwords = [word for word in TSPwords if checkWord(word)]\n",
    "TBDwords = [word for word in TBDwords if checkWord(word)]\n",
    "TGGwords = [word for word in TGGwords if checkWord(word)]\n",
    "#print (TSPwords)\n",
    "\n",
    "#print (TSPwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vecortizing the Books: looking for scaled occurence\n",
    "\n",
    "##### counting words\n",
    "\n",
    "I have to decide if i want to keep character names in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "dictionaryTSP = Counter()\n",
    "dictionaryTBD = Counter()\n",
    "dictionaryTGG = Counter()\n",
    "\n",
    "dictionaryTSP.update(TSPwords)\n",
    "\n",
    "dictionaryTBD.update(TBDwords)\n",
    "dictionaryTGG.update(TGGwords)\n",
    "\n",
    "#print (dictionaryTBD)\n",
    "\n",
    "\n",
    "#print (dictionaryTSP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print (dictionaryTGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print (dictionaryTSP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I should try to get rid of some mroe fo the wrods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'amory': 882, 'beatrice': 43, 'isabelle': 78, 'rosalind': 192}, {'anthony': 922, 'dot': 36, 'dick': 155, 'gloria': 578}, {'gatsby': 259, 'tom': 190, 'daisy': 182, 'jordan': 73}]\n"
     ]
    }
   ],
   "source": [
    "def instanesOfCharacters(n, book):\n",
    "    tempDict = {}\n",
    "    for key, value in n.items():\n",
    "        if key in book:\n",
    "            tempDict[key] = value\n",
    "            \n",
    "    return tempDict\n",
    "\n",
    "\n",
    "TSPCharacterList = instanesOfCharacters(dictionaryTSP, TSPCharacters)\n",
    "TBDCharacterList = instanesOfCharacters(dictionaryTBD, TBDCharacters)\n",
    "TGGCharacterList = instanesOfCharacters(dictionaryTGG, TGGCharacters)\n",
    "\n",
    "#print (TSPCharacterList)\n",
    "#print (TBDCharacterList)\n",
    "#print (TGGCharacterList)\n",
    "            \n",
    "        \n",
    "AllCharacterList = [TSPCharacterList, TBDCharacterList, TGGCharacterList]\n",
    "print (AllCharacterList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findTrackWords(n):\n",
    "    tempDict = {}\n",
    "    for key, value in n.items():\n",
    "        if key in trackWords:\n",
    "            tempDict[key] = value\n",
    "    return tempDict\n",
    "\n",
    "TSPtrackWords = findTrackWords(dictionaryTSP)\n",
    "TBDtrackWords = findTrackWords(dictionaryTBD)\n",
    "TGGtrackWords = findTrackWords(dictionaryTGG)\n",
    "\n",
    "#print (TSPtrackWords)\n",
    "#print (TBDtrackWords)\n",
    "#print (TGGtrackWords)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'heart': 30, 'girl': 88, 'city': 14, 'white': 28, 'love': 83, 'money': 33}, {'money': 78, 'city': 46, 'heart': 48, 'girl': 103, 'love': 84, 'white': 52}, {'heart': 19, 'city': 20, 'money': 23, 'white': 45, 'girl': 47, 'love': 24}]\n"
     ]
    }
   ],
   "source": [
    "trackWordsAll = [TSPtrackWords, TBDtrackWords, TGGtrackWords]\n",
    "print (trackWordsAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'heart': 30, 'girl': 88, 'city': 14, 'white': 28, 'love': 83, 'money': 33}, {'money': 78, 'city': 46, 'heart': 48, 'girl': 103, 'love': 84, 'white': 52}, {'heart': 19, 'city': 20, 'money': 23, 'white': 45, 'girl': 47, 'love': 24}]\n",
      "[{'amory': 882, 'beatrice': 43, 'isabelle': 78, 'rosalind': 192}, {'anthony': 922, 'dot': 36, 'dick': 155, 'gloria': 578}, {'gatsby': 259, 'tom': 190, 'daisy': 182, 'jordan': 73}]\n"
     ]
    }
   ],
   "source": [
    "print (trackWordsAll)\n",
    "print (AllCharacterList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is commented out becuase I decided to not use this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def findWordsThatAreInAllThree(TSP, TBD, TGG):\n",
    "#     tempArr = []\n",
    "#     for key, value in TSP.items():\n",
    "#         subDict = {}\n",
    "#         if key in TBD.keys() and key in TGG.keys() and value > 5:\n",
    "#             tempArr.append(key)            \n",
    "#     return tempArr\n",
    "            \n",
    "# wordsInAll = findWordsThatAreInAllThree(dictionaryTSP, dictionaryTBD, dictionaryTGG)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'amory': 882, 'beatrice': 43, 'isabelle': 78, 'rosalind': 192}, {'anthony': 922, 'dot': 36, 'dick': 155, 'gloria': 578}, {'gatsby': 259, 'tom': 190, 'daisy': 182, 'jordan': 73}]\n",
      "102967\n",
      "151556\n",
      "59922\n"
     ]
    }
   ],
   "source": [
    "print (AllCharacterList)\n",
    "print (TSPlength)\n",
    "print (TBDlength)\n",
    "print (TGGlength)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will allow create 2D arrays that I can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['amory', 882, 'TSP'], ['beatrice', 43, 'TSP'], ['isabelle', 78, 'TSP'], ['rosalind', 192, 'TSP'], ['anthony', 922, 'TBD'], ['dot', 36, 'TBD'], ['dick', 155, 'TBD'], ['gloria', 578, 'TBD'], ['gatsby', 259, 'TGG'], ['tom', 190, 'TGG'], ['daisy', 182, 'TGG'], ['jordan', 73, 'TGG']]\n"
     ]
    }
   ],
   "source": [
    "def makeUsable(n1, book1, n2, book2, n3, book3):\n",
    "    arr = []\n",
    "    for key, val in n1.items():\n",
    "        subArr = [key, val, book1]\n",
    "        arr.append(subArr)\n",
    "    for key, val in n2.items():\n",
    "        subArr = [key, val, book2]\n",
    "        arr.append(subArr)\n",
    "    for key, val in n3.items():\n",
    "        subArr = [key, val, book3]\n",
    "        arr.append(subArr)\n",
    "    return arr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AllCharacterList = makeUsable(TSPCharacterList, 'TSP', TBDCharacterList, 'TBD', TGGCharacterList, 'TGG')\n",
    "print (AllCharacterList)\n",
    "\n",
    "trackWordsAll = makeUsable(TSPtrackWords, 'TSP', TBDtrackWords, 'TBD', TGGtrackWords, 'TGG')\n",
    "#print (trackWordsAll)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have manually put this dataset into a js file that I have linked to in my index.html. I use it in the format that it exists in now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeUsableDF(arr):\n",
    "    for key, val in n1.items():\n",
    "        arr.append(val)\n",
    "    for key, val in n2.items():\n",
    "        arr.append(val)\n",
    "    for key, val in n3.items():\n",
    "        arr.append(val)\n",
    "    return arr\n",
    "\n",
    "\n",
    "\n",
    "#print (makeUsableDF(TSPtrackWords, TBDtrackWords, TGGtrackWords))\n",
    "# def makeDFable()\n",
    "df = pd.DataFrame(trackWordsAll)\n",
    "df = pd.DataFrame(trackWordsAll, index=[df[0],df[2]])\n",
    "df1 = df.unstack()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TBD  TGG  TSP\n",
      "0                   \n",
      "city    46   20   14\n",
      "girl   103   47   88\n",
      "heart   48   19   30\n",
      "love    84   24   83\n",
      "money   78   23   33\n",
      "white   52   45   28\n"
     ]
    }
   ],
   "source": [
    "df1.columns = [\"TBD\", \"TGG\", \"TSP\"]\n",
    "print(df1)\n",
    "\n",
    "df1.to_csv(\"track_words_new\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
